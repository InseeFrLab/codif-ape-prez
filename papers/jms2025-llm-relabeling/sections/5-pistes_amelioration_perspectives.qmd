Plusieurs pistes peuvent être explorées pour renforcer la qualité, l’efficacité et l’utilité de cette démarche. Un premier axe consiste à tester régulièrement des modèles de langage plus récents et à réévaluer la méthode sur des données plus actuelles que celles de la baseline, afin de mesurer les gains apportés par les nouvelles générations de LLM et de garantir l’adéquation aux pratiques et besoins métiers.

L’optimisation de l’inférence constitue un autre levier important. L’inférence par lots mobilise fortement les ressources de calcul, en particulier les GPU. Des améliorations sont possibles en optimisant le code, en affinant la gestion des lots et en choisissant des architectures logicielles et matérielles plus adaptées. Une approche plus sobre et alignée avec les principes du Green IT permettrait de réduire le coût énergétique des traitements et de favoriser des usages plus frugaux.

Le renforcement du RAG représente également une voie prometteuse. L’amélioration du retrieval, l’intégration de rerankers et une exploitation plus fine de la structure hiérarchique des nomenclatures pourraient permettre de mieux guider le modèle. Une évaluation plus précise permettrait de distinguer les erreurs liées à la recherche d’information de celles liées à la génération. Ces travaux pourraient être approfondis conjointement par le SSP Lab et les data scientists proches du métier pour identifier les cas où un RAG robuste compléterait efficacement le CAG.

Des perspectives existent aussi autour des approches agentiques. Un agent peut structurer sa réponse en plusieurs étapes de raisonnement, ce qui pourrait améliorer la qualité et l’interprétabilité du processus de codification. Les cas d’usage restent à explorer et pourraient dépasser le seul recodage du jeu d’apprentissage. Par exemple, une assistance interactive à la codification pour les gestionnaires pourrait être envisagée. Cette approche soulève néanmoins des défis d’inférence, notamment en matière de latence et de propagation d’erreurs. Une stratégie distincte peut consister à guider le codage par un cheminement progressif dans la nomenclature, de la section jusqu’au niveau sous-classe, afin d’améliorer la sélection du code final.

L’enrichissement du contexte par des sources internes ou externes constitue également un levier d’amélioration. La consultation de documents métiers supplémentaires ou de ressources issues de recherches Internet peut aider à clarifier certains termes présents dans les libellés, réduire les ambiguïtés et limiter les erreurs d’interprétation, notamment lorsque le vocabulaire est spécialisé ou polysémique. L’utilisation de nomenclatures complémentaires, comme la CPF (Classification des Produits Française), peut aussi apporter un contexte utile. La CPF classe l’économie à un niveau plus fin, au niveau des produits, biens et services. Elle peut s’avérer précieuse lorsque les libellés sont très précis et que plusieurs sous-classes NAF sont envisageables, car elle fournit des éléments concrets permettant de remonter au bon code en distinguant plus clairement la nature du produit ou du service associé. C’est d’ailleurs une pratique couramment utilisée par les experts et gestionnaires lorsqu’ils rencontrent ce type de difficulté, afin de conforter ou affiner le choix du code.

Cette expérimentation ouvre aussi des perspectives pour la mise en production et la maintenance des modèles. Les LLM peuvent soutenir les experts en facilitant le traitement de cas répétitifs ou longs à expertiser et en produisant des annotations utiles pour un meilleur suivi de la qualité, par exemple en surveillant la stabilité de la précision dans le temps afin de détecter des dérives. Toutefois, l’usage de LLM en production est limité par le coût, la latence et les besoins en GPU. En l'absence de moyens, il semble plus réaliste de les mobiliser de manière ponctuelle pour du suivi, de l’audit, de la préqualification de corpus ou des analyses ciblées. Les équipes métier peuvent contribuer à définir les cas d’usage où ces apports seraient les plus utiles. De leur côté, les équipes d’innovation informatique pourront étudier les solutions technologiques susceptibles d’intégrer ce type d’outils de manière plus sobre, fiable et maintenable.

Par ailleurs, si l’on devait imaginer ce type d’outils en production, plusieurs enjeux transverses devraient être anticipés. Sur le plan métier, il faudrait définir précisément les cas d’usage apportant une valeur ajoutée tangible. Sur le plan technique, les choix de modèles et d’architectures auraient un impact notable en termes de coûts et d’empreinte énergétique, renforçant la nécessité de privilégier des solutions plus frugales. L’intégration de LLM dans des chaînes opérationnelles introduirait également des défis de maintenance et de gouvernance, relevant de pratiques plus avancées que le MLOps actuel. Cela touche au domaine émergent du LLMops, incluant la gestion du contexte, des prompts, des versions de modèles et de la qualité de génération, et nécessiterait une montée en compétences et une collaboration renforcée entre experts métier, data science et innovation informatique.

Ces perspectives s’inscrivent dans la continuité des résultats obtenus et prolongent la conclusion en montrant que les LLM peuvent apporter de nouvelles capacités, tout en devant être utilisés avec discernement et en complément des expertises métier.

Enfin, les enseignements tirés dépassent le cadre de la NAF et de l’Insee. La démarche peut inspirer d’autres projets de codification ou d’usages de LLM dans d’autres instituts nationaux de statistique. Les méthodes testées pour le recodage, l’inférence par lots, le développement de bases d’apprentissage, l’usage raisonné du RAG et l’apport de l’agentique peuvent être adaptées à d’autres nomenclatures et mises en partage au sein de la communauté statistique internationale.

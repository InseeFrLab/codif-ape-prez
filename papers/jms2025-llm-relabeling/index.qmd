---
title: "Changement de nomenclature statistique à l'ère du Machine Learning: réentraînement basé sur les LLM (Large Language Models) pour la révision de la NAF"
authors:
  - name: Nathan Randriamanana
    affiliation: Insee, Direction des statistiques d'entreprises
    email: <nathan.randriamanana@insee.fr>
  - name: Thomas Faria
    affiliation: Insee, Direction de la méthodologie et de la coordination statistique et internationale
    email: <thomas.faria@insee.fr>
keywords: # 6 maximum
  - codification automatique
  - classification de texte
  - prompt
  - annotation
  - révision de nomenclature
domains: # utiliser la nomenclature du site (menu déroulant) --> a modifier
  - science des données
  - codification automatique
  - analyse du langage naturel
resume: |
    La **Nomenclature d’activités française (NAF)** a connu une révision en décembre 2023.
    Dès lors, le passage de la NAF rév. 2 à la NAF 2025 impacte la codification automatique de l’Activité Principale Exercée (APE) des entreprises, à partir de sa description littérale. Cette codification représente un enjeu opérationnel majeur pour l'Insee, en particulier pour le répertoire _Sirene_ (Système national d'identification et du répertoire des entreprises et de leurs établissements) qui est le garant de l'APE pour les autres administrations.
    Au quotidien, le code APE se retrouve notamment dans les déclarations sociales et fiscales, les bulletins de paie, les tickets de caisse et bientôt dans la facturation numérique. Au-delà de classer les entreprises par secteur d'activité dans le but de produire des statistiques et de réaliser des analyses, pour un objectif d'information économique et sociale, son impact dépasse largement la sphère de l'Insee. Le code APE a des impacts transversaux sur l'ensemble de l'écosystème économique, ses partenaires et ses clients. Sa révision se propage en cascade aux systèmes d'information des partenaires ou clients.
    Pour Sirene, la question se pose de savoir comment construire un modèle probabiliste capable d'attribuer le code APE en nouvelle nomenclature, malgré l'absence naturelle de données d'apprentissage, à partir du libellé décrivant l'APE et sa valeur en ancienne nomenclature.
   
    L'article présente, premièrement, le contexte de la récente refonte de Sirene 3 à **Sirene 4**. 
    Pour traiter les formalités d'entreprises en flux, l'application a intégré la **mise en production** d'un modèle de _machine learning_ pour la codification automatique de l'APE, via la librairie _fastText_, depuis novembre 2022, pour remplacer l'ancien système expert Sicore: un choix technologique essentiel pour gérer le volume, la fréquence et la variété des descriptions textuelles soumises par les entreprises via le portail du Guichet Unique des Entreprises.

    La seconde partie de l'article présente les enjeux d'annotation et le travail préparatoire des experts pour constituer la **vérité terrain** (ou _ground truth_).
    Jusqu'ici l'entraînement du modèle se repose sur une base d'entraînement constituée d'exemples historiques. Le changement de nomenclature rend caduque la base d'entraînement dès lors qu'il existe des codes NAF **multivoques**, c'est-à-dire qu'il existe plus d'une seule correspondance entre un code de l'ancienne version de la nomenclature et la nouvelle. Ainsi, il n'est pas possible de recoder tous les codes de la base par une bijection. A priori, en l'absence totale de données, une intervention manuelle de la part d'experts de la codification de l'APE est donc nécessaire pour **compléter la base d'entraînement**. Une vaste campagne d'annotation a donc eu lieu au second semestre de 2024 pour **obtenir des données en nouvelle nomenclature**.
      
    Toutefois, la campagne d'annotation pose un problème d'échelle critique puisque la capacité d'annotation des experts est limitée à environ 30 000 libellés, alors que le volume à traiter excède le million d'observations. Les stratégies métiers, telles que la requalification de codes à correspondance multivoque en biunivoque et la limitation aux multivoques, ne suffisent pas à réduire significativement cet écart. Or, pour maintenir un taux de codification satisfaisant en production et ainsi alléger la charge de reprise gestionnaire, notre modèle fastText requiert un corpus d'entraînement varié et massif (des millions d'observations). 
    Compte tenu des contraintes de charge, il est **impossible voire contre-productif de mobiliser la seule force des experts pour constituer l'exhaustivité** de la base d'apprentissage requise. 

    Face à ce volume critique de données manquantes, la troisième partie de l'article présente une méthodologie innovante afin de reconstituer un jeu de données massives en NAF 2025 en particulier sur les cas multivoques en s'appuyant sur le travail et le mode opératoire des experts pour entraîner un modèle de codification automatique performant en production. La méthodologie de génération de texte présentée s'articulera sur des stratégies de génération augmentée s'appuyant sur l'usage de **Large Language Models (LLM)**, architecture actuellement la plus courante pour l'IA générative textuelle. 
    La quatrième partie est consacrée aux résultats du réentrainement, la qualification et les enjeux de surveillance du prochain modèle en production en NAF 2025.

    Ce sujet de réentrainement de modèles probabilistes suite à un changement de nomenclature peut intéresser plusieurs instituts nationaux de statistiques (INS), particulièrement pour les équipes concernées par le passage à la NACE rev 2.1. 
    Outre la thématique de l'APE, les stratégies présentées ne sont pas restreintes à une nomenclature ou un modèle de codification automatique particuliers, sous réserve de disposer de notes explicatives de la nomenclature en question et de capacité d'évaluation.

abstract: |
    The overhaul of the French Nomenclature of Activities (NAF 2025) creates a critical training challenge for the automatic main activity code (APE) coding model used by the French administrative register Sirene.
    Business creators in France use a one-stop shop to complete their administrative procedures. In particular, they describe their main activity in writing. This activity is then coded in the NAF by INSEE using an automatic coding model based on machine learning.
    While the model handles the coding task, its performance requires a massive training corpus (millions of observations). The transition invalidates historical data for ambiguous cases, and manual expert annotation capacity is severely limited and unsustainable for generating the required volume. To overcome this initial data deficit crucial to model retraining, the presented work introduces an innovative methodology. The solution leverages Augmented Generation Techniques based on Large Language Models (LLMs) to generate the full NAF 2025 training base. 
    This approach models expert operational logic, providing a scalable, reliable, and replicable solution for any National Statistical Institute facing a nomenclature change.
bibliography: biblio.bib
format:
  jms2025-typst:
    logo:
      location: center-top # ne pas modifier
      width: 160mm # ne pas modifier
    mainfont: "tex gyre heros" # peut être modifié pour "calibri" sous windows, voir le script install-fonts.sh
    footer: 15^e^ édition des journées de méthodologie statistique de l'Insee (JMS 2025) # ne pas modifier
    section-numbering: 1.1.1.
    keep-typ: true
---

{{< pagebreak >}}

# Introduction {.unnumbered}

{{< include sections/0-introduction.qmd >}}

{{< pagebreak >}}

# La codification APE dans Sirene 4, une nouvelle application pour traiter les déclarations d'entreprises en continu 

{{< include sections/1-prod.qmd >}}

# Comment convertir notre base d'apprentissage en NAF 2025 ? campagne d'annotation et vérité terrain

{{< include sections/2-naf.qmd >}}

# Comment générer une base d'apprentissage en nouvelle nomenclature sur la base de la vérité terrain ?

{{< include sections/3-methodo.qmd >}}

# Réentraînement en NAF 2025 {#rentrainement}

{{< include sections/4-reentrainement.qmd >}}

# Pistes d'amélioration et perspectives 

{{< include sections/5-pistes_amelioration_perspectives.qmd >}}

{{< pagebreak >}}
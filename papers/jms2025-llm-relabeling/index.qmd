---
title: "Changement de nomenclature statistique à l'ère du Machine Learning: réentraînement basé sur les LLM (Large Language Models) pour la révision de la NAF"
authors:
  - name: Nathan Randriamanana
    affiliation: Insee, Direction des statistiques d'entreprises
    email: <nathan.randriamanana@insee.fr>
  - name: Thomas Faria
    affiliation: Insee, Direction de la méthodologie et de la coordination statistique et internationale
    email: <thomas.faria@insee.fr>
keywords: # 6 maximum
  - codification automatique
  - classification de texte
  - prompt
  - annotation
  - révision de nomenclature
domains: # utiliser la nomenclature du site (menu déroulant) --> a modifier
  - science des données
  - codification automatique
  - analyse du langage naturel
resume: |
    La **Nomenclature d’activités française (NAF)** a connu une rénovation en décembre 2023.
    Dès lors, le passage de la NAF rév. 2 à la NAF 2025 impacte la codification automatique de l’Activité Principale Exercée (APE) des entreprises, aussi appelé code NAF, à partir de textes. Cette codification représente un enjeu opérationnel majeur pour l'Insee, en particulier pour le répertoire _Sirene_ (Système national d'identification et du répertoire des entreprises et de leurs établissements).
    Au quotidien, le code APE se retrouve notamment dans les déclarations sociales et fiscales, les bulletins de paie, les tickets de caisse et bientôt dans la facturation numérique. Au-delà de classer les entreprises par secteur d'activité dans le but de produire des statistiques et de réaliser des analyses, pour un objectif d'information économique et sociale, son impact dépasse largement la sphère de l'Insee. 
    Le code APE étant une donnée structurante généralisée, sa mise à jour génère des impacts transversaux cruciaux sur l'ensemble de l'écosystème économique, ses partenaires et ses clients. Sa modification se propage en cascade à tous les systèmes d'information utilisés par les entreprises, leurs partenaires et leurs clients.
    Pour Sirene, la question se pose de savoir comment construire un modèle probabiliste capable d'attribuer le code APE en nouvelle nomenclature, malgré l'absence naturelle de données d'apprentissage. 
   
    L'article présente, en première partie, le contexte de la nouvelle refonte de Sirene: **Sirene 4**. 
    Pour traiter les formalités d'entreprises en flux, l'application a intégré un modèle de _machine learning_ pour la codification automatique de l'APE, via la librairie _fastText_. Mis **en production** depuis novembre 2022, ce modèle remplace l'ancien système expert Sicore, constituant un choix technologique essentiel pour gérer le volume, la fréquence et la variété des descriptions textuelles soumises par les entreprises via le portail du Guichet Unique des Entreprises.

    La seconde partie de l'article présente les enjeux de labellisation et le travail préparatoire des experts pour constituer la **vérité terrain** (communément ground truth).
    Jusqu'ici l'entraînement du modèle se repose sur une base d'entraînement s'appuyant sur des exemples historiques rencontrés **en production**. Le changement de nomenclature rend caduque la base d'entraînement dès lors qu'il existe des codes NAF **multivoques**, c'est-à-dire qu'il existe plus d'une seule correspondance entre un code de l'ancienne version de la nomenclature et la nouvelle. Ainsi, il n'est pas possible de recoder tous les codes de la base par une bijection. A priori, en l'absence totale de données, une intervention manuelle de la part d'experts de la codification de l'APE est donc nécessaire pour **compléter la base d'entraînement**.
    Une vaste campagne d'annotation a donc eu lieu au second semestre de 2024 pour **entraîner un classifieur pouvant coder en nouvelle nomenclature**.
      
    Toutefois, la campagne d'annotation pose un problème d'échelle critique puisque la capacité d'annotation des experts est limitée à environ 30 000 libellés, alors que le volume à traiter excède le million d'observations. Les stratégies métiers, telles que la requalification de codes à correspondance multivoque en biunivoque et la limitation aux multivoques, ne suffisent pas à réduire significativement cet écart. Or, pour maintenir un taux de codification satisfaisant en production et ainsi alléger la charge des gestionnaires (en flux), notre modèle fastText requiert un corpus d'entraînement varié et massif (de l'ordre des millions d'observations). 
    Compte tenu des contraintes de charge, il est **impossible voire contre-productif de mobiliser la seule force des experts pour constituer l'exhaustivité** de la base d'apprentissage requise. 

    Face à ce volume critique de données manquantes, la troisième partie de l'article présente une méthodologie innovante afin de reconstituer un jeu de données massives en NAF 2025 en particulier sur les cas multivoques en s'appuyant sur le travail et le mode opératoire des experts pour entraîner un modèle de codification automatique performant en production. La méthodologie de génération de texte présentée s'articulera sur des stratégies de génération augmentée s'appuyant sur l'usage de **Large Language Models (LLM)**, architecture actuellement la plus courante pour l'IA générative textuelle. Puis, seront abordés les résultats du réentrainement, la qualification et les enjeux de surveillance du prochain modèle en production en NAF 2025.

    Ce sujet de réentrainement de modèles probabilistes suite à un changement de nomenclature peut intéresser plusieurs instituts nationaux de statistiques, particulièrement pour les équipes concernées par le passage à la NACE rev 2.1. 
    Outre la thématique de l'APE, les stratégies présentées sont également transposables à d'autres systèmes de codification impactés par un changement de nomenclature. 
    Elles ne sont pas restreintes à une nomenclature ou un modèle de codification automatique particuliers, sous réserve de disposer de notes explicatives de la nomenclature en question et de capacité d'évaluation.

abstract: |
    The overhaul of the French Nomenclature of Activities (NAF 2025) creates a critical training challenge for the automatic APE coding model used by the Sirene registry. While the model handles the coding task, its performance requires a massive training corpus (millions of observations). The transition invalidates historical data for ambiguous cases, and manual expert annotation capacity is severely limited and unsustainable for generating the required volume. To overcome this initial data deficit crucial to model retraining, the presented work introduces an innovative methodology. The solution leverages Augmented Generation Techniques based on Large Language Models (LLMs) to generate the full NAF 2025 training base. 
# This approach models expert operational logic, providing a scalable, reliable, and replicable solution for any National Statistical Institute facing a nomenclature change.
bibliography: biblio.bib
format:
  jms2025-typst:
    logo:
      location: center-top # ne pas modifier
      width: 160mm # ne pas modifier
    mainfont: "tex gyre heros" # peut être modifié pour "calibri" sous windows, voir le script install-fonts.sh
    footer: 15^e^ édition des journées de méthodologie statistique de l'Insee (JMS 2025) # ne pas modifier
    section-numbering: 1.1.1.
    keep-typ: true
---

{{< pagebreak >}}

# Introduction {.unnumbered}

{{< include sections/0-introduction.qmd >}}

{{< pagebreak >}}

# L'application Sirene 4: une nouvelle application embarquant de la codification automatique de données en flux

{{< include sections/1-prod.qmd >}}

{{< pagebreak >}}

# Construction de la nouvelle nomenclature et d'une vérité terrain, des besoins de nouvelles données

{{< include sections/2-naf.qmd >}}

{{< pagebreak >}}

# Comment générer une base d'apprentissage en nouvelle nomenclature sur la base de la vérité terrain ?

{{< include sections/3-methodo.qmd >}}

{{< pagebreak >}}

# Réentraînement en NAF 2025 {#rentrainement}

{{< include sections/4-reentrainement.qmd >}}

{{< pagebreak >}}

# Pistes d'amélioration et perspectives 

{{< include sections/5-pistes_amelioration_perspectives.qmd >}}

{{< pagebreak >}}
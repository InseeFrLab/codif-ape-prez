---
title: "Changement de nomenclature statistique à l'ère du Machine Learning: réentraînement basé sur les LLM (Large Language Models) pour la révision de la NAF"
authors:
  - name: Nathan Randriamanana
    affiliation: Insee, Direction des statistiques d'entreprises
    email: <nathan.randriamanana@insee.fr>
  - name: Thomas Faria
    affiliation: Insee, Direction de la méthodologie et de la coordination statistique et internationale
    email: <thomas.faria@insee.fr>
keywords: # 6 maximum
  - codification automatique
  - classification de texte
  - prompt
  - annotation
  - révision de nomenclature
domains: # utiliser la nomenclature du site (menu déroulant) --> a modifier
  - science des données
  - codification automatique
  - analyse du langage naturel
resume: |
    La **Nomenclature d’activités française (NAF)** a connu une rénovation en décembre 2023.
    Dès lors, le passage de la NAF rév. 2 à la NAF 2025 impacte la codification automatique de l’Activité Principale Exercée (APE), aussi appelé code NAF, à partir de libellés textuels. Cette codification représente un enjeu opérationnel majeur pour l'Insee, en particulier pour le répertoire *Sirene* (Système national d'identification et du répertoire des entreprises et de leurs établissements).
    Au quotidien, le code APE se retrouve notamment dans les déclarations sociales et fiscales, les bulletins de paie, les tickets de caisse et bientôt dans la facturation numérique. Au-delà de classer les entreprises par secteur d'activité dans le but de produire des statistiques et de réaliser des analyses, pour un objectif d'information économique et sociale, son impact dépasse largement la sphère de l'Insee. 
    Le code APE étant une donnée structurante généralisée, sa mise à jour génère des impacts transversaux cruciaux sur l'ensemble de l'écosystème économique, ses partenaires et ses clients. Sa modification se propage en cascade à tous les systèmes d'information utilisés par les entreprises, leurs partenaires et leurs clients.
    Pour Sirene, la question se pose de savoir comment construire un modèle probabiliste capable d'attribuer le code APE en nouvelle nomenclature, malgré l'absence naturelle de données d'apprentissage. 
    
    Depuis novembre 2022, un modèle *fastText* de *machine learning*, rapide et répondant aux écueils du précédent système expert *Sicore*, est **utilisé en production** par l'application *Sirene* pour la codification automatique de l'APE.

    La première partie de l'article présente les enjeux de labellisation et le travail préparatoire des experts pour constituer la **vérité terrain** (communément ground truth).
    Jusqu'ici l'entraînement du modèle se repose sur une base d'entraînement s'appuyant sur des exemples historiques rencontrés **en production**. Le changement de nomenclature rend caduque la base d'entraînement dès lors qu'il existe des codes NAF **multivoques**, c'est-à-dire qu'il existe plus d'une seule correspondance entre un code de l'ancienne version de la nomenclature et la nouvelle. Ainsi, il n'est pas possible de recoder tous les codes de la base par une bijection. A priori, en l'absence totale de données, une intervention manuelle de la part d'experts de la codification de l'APE est donc nécessaire pour **compléter la base d'entraînement**.
    Une vaste campagne d'annotation a donc eu lieu au second semestre de 2024 pour **entraîner un classifieur pouvant coder en nouvelle nomenclature**.
      
    Toutefois, la campagne d'annotation pose un problème d'échelle critique puisque la capacité d'annotation des experts est limitée à environ 30 000 libellés, alors que le volume à traiter excède le million d'observations. Les stratégies métiers, telles que la requalification de codes à correspondance multivoque en biunivoque et la limitation aux multivoques, ne suffisent pas à réduire significativement cet écart. Or, pour maintenir un taux de codification satisfaisant en production et ainsi alléger la charge des gestionnaires (en flux), notre modèle fastText requiert un corpus d'entraînement varié et massif (de l'ordre des millions d'observations). 
    Compte tenu des contraintes de charge, il est **impossible voire contre-productif de mobiliser la seule force des experts pour constituer l'exhaustivité** de la base d'apprentissage requise. 

    Face à ce volume critique de données manquantes, la seconde partie de l'article présente une méthodologie afin de reconstituer un jeu de données massives en NAF 2025 en particulier sur les cas multivoques en s'appuyant sur le travail et le mode opératoire des experts pour entraîner un modèle de codification automatique performant en production. La méthodologie de génération de texte présentée s'articulera sur des stratégies de génération augmentée s'appuyant sur l'usage de **Large Language Models (LLM)**, architecture actuellement la plus courante pour l'IA générative textuelle.

    Ce sujet de réentrainement de modèles probabilistes suite à un changement de nomenclature peut intéresser plusieurs instituts nationaux de statistiques, particulièrement pour les équipes concernées par le passage à la NACE rev 2.1. 
    Outre la thématique de l'APE, les stratégies présentées sont également transposables à d'autres systèmes de codification impactés par un changement de nomenclature. 
    Elles ne sont pas restreintes à une nomenclature ou un modèle de codification automatique particuliers, sous réserve de disposer de notes explicatives de la nomenclature en question et de capacité d'évaluation.

abstract: |
    The overhaul of the French Nomenclature of Activities (NAF 2025) creates a critical training challenge for the automatic APE coding model used by the Sirene registry. While the model handles the coding task, its performance requires a massive training corpus (millions of observations). The transition invalidates historical data for ambiguous cases, and manual expert annotation capacity is severely limited and unsustainable for generating the required volume. To overcome this initial data deficit crucial to model retraining, the presented work introduces an innovative methodology. The solution leverages Augmented Generation Techniques based on Large Language Models (LLMs) to reconstitute the full NAF 2025 training base. This approach models expert operational logic, providing a scalable, reliable, and replicable solution for any National Statistical Institute facing a nomenclature change.
bibliography: biblio.bib
format:
  jms2025-typst:
    logo:
      location: center-top # ne pas modifier
      width: 160mm # ne pas modifier
    mainfont: "tex gyre heros" # peut être modifié pour "calibri" sous windows, voir le script install-fonts.sh
    footer: 15^e^ édition des journées de méthodologie statistique de l'Insee (JMS 2025) # ne pas modifier
    section-numbering: 1.1.1.
    keep-typ: true
---

{{< pagebreak >}}

# Introduction

{{< include sections/1-introduction.qmd >}}

{{< pagebreak >}}

# Construction de la nouvelle NAF et de la vérité terrain

{{< include sections/2-manuel.qmd >}}

{{< pagebreak >}}

# Méthodologie

{{< include sections/3-methodo.qmd >}}

{{< pagebreak >}}

# Résultats {#resultats}

{{< include sections/4-resultats.qmd >}}

{{< pagebreak >}}

# Pistes d'amélioration et perspectives 

{{< include sections/5-pistes_amelioration_perspectives.qmd >}}

{{< pagebreak >}}